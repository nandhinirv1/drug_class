{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19533, 27)\n"
     ]
    }
   ],
   "source": [
    "#Clinical trial phase wise input data merge\n",
    "#These tsvs were downloaded phase wise from the clinicaltrials.gov link provided in the case study document\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "early_phase = pd.read_csv(\"Early_phase.tsv\",delimiter='\\t',header = 0)\n",
    "phase1 = pd.read_csv(\"Phase1.tsv\",delimiter='\\t',header = 0)\n",
    "phase2 = pd.read_csv(\"Phase2.tsv\",delimiter='\\t',header = 0)\n",
    "phase3 = pd.read_csv(\"Phase3.tsv\",delimiter='\\t',header = 0)\n",
    "phase4 = pd.read_csv(\"Phase4.tsv\",delimiter='\\t',header = 0)\n",
    "not_applicable = pd.read_csv(\"Not_Applicable.tsv\",delimiter='\\t',header = 0)\n",
    "\n",
    "\n",
    "base = pd.concat([early_phase,phase1,phase2,phase3,phase4,not_applicable])\n",
    "print (base.shape)\n",
    "#print(early_phase.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank\n",
      "NCT Number\n",
      "Title\n",
      "Acronym\n",
      "Status\n",
      "Study Results\n",
      "Conditions\n",
      "Interventions\n",
      "Outcome Measures\n",
      "Sponsor/Collaborators\n",
      "Gender\n",
      "Age\n",
      "Phases\n",
      "Enrollment\n",
      "Funded Bys\n",
      "Study Type\n",
      "Study Designs\n",
      "Other IDs\n",
      "Start Date\n",
      "Primary Completion Date\n",
      "Completion Date\n",
      "First Posted\n",
      "Results First Posted\n",
      "Last Update Posted\n",
      "Locations\n",
      "Study Documents\n",
      "URL\n"
     ]
    }
   ],
   "source": [
    "for col in base.columns:\n",
    "    print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genetic: SGT-53', 'Radiation: Radiation', 'Drug: Irinotecan', 'Drug: Temozolomide', 'Drug: Bevacizumab']\n",
      "19533\n",
      "[' SGT-53', ' Irinotecan', ' Temozolomide', ' Bevacizumab']\n",
      "19533\n"
     ]
    }
   ],
   "source": [
    "base[\"intervention_list\"] = base.apply(lambda x:x['Interventions'].split(\"|\"), axis=1)\n",
    "#print (base.head(n=5))\n",
    "interventions = base[\"intervention_list\"].tolist()\n",
    "#print (interventions[1])\n",
    "i=0\n",
    "only_drugs=[]\n",
    "for intervention in interventions:\n",
    "    i=i+1\n",
    "    drug=[]\n",
    "    for sub in intervention:\n",
    "        #Excluding non-drugs with the in []\n",
    "        if (len((sub.split(\":\")))>1) and (sub.split(\":\")[0]  in [\"Drug\", \"Genetic\" ,\"Biological\",\"Combination Product\"]) and (\"placebo\" not in sub.lower()):\n",
    "            drug.append(sub.split(\":\")[1])\n",
    "        else:\n",
    "            pass\n",
    "    only_drugs.append(drug)\n",
    "print (interventions[1])\n",
    "print (len(interventions))\n",
    "print (only_drugs[1])\n",
    "print (len(only_drugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import spacy\n",
    "i=0\n",
    "search_list=[]\n",
    "for drug_list in only_drugs:\n",
    "    i=i+1\n",
    "    search=[]\n",
    "    for drug in drug_list:\n",
    "        tokens=pos_tag(word_tokenize(drug))\n",
    "        temp=[]\n",
    "        for tag in tokens:\n",
    "            if tag[1] in [\"NNP\",\"NN\",\"JJ\"] and len(tag[0])>3 and len(wordnet.synsets(tag[0].lower()))<=1:\n",
    "                temp.append(tag[0])\n",
    "            else:\n",
    "                pass\n",
    "        search.append(temp)\n",
    "    search_list.append(search)\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "        #print (search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceptions:\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ids=base[\"NCT Number\"].tolist()\n",
    "\n",
    "ids_drugs=list(zip(ids,search_list))\n",
    "\n",
    "#print (ids_drugs[17999])\n",
    "\n",
    "# The commented out code writes the combination of keywords found for the drug in question, for example metformin hydrochloride\n",
    "# Currently the code writes two rows for metformin and hydrochloride.\n",
    "# There are pro and cons of doing it either ways which can be explained over the call\n",
    "\n",
    "with open (\"ct_id_drug.txt\",\"a\") as fw:\n",
    "    i=0\n",
    "    for combo in ids_drugs:\n",
    "        try:\n",
    "            id=combo[0]\n",
    "            drugs=combo[1]\n",
    "            for drug in drugs:\n",
    "                for item in drug:#\n",
    "                    #fw.write(id+\"\\t\"+\" \".join(x for x in drug).strip()+\"\\n\")\n",
    "                    fw.write(id+\"\\t\"+item.strip()+\"\\n\")\n",
    "        except:\n",
    "            i=i+1\n",
    "        \n",
    "print (\"Exceptions:\")\n",
    "print (i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
